# AVNet
# EmoNet Fine-Tuning ‚Äî `train_emonet.py`

A PyTorch script for **transfer learning on EmoNet**, supporting **Valence‚ÄìArousal (VA) regression** and optional **facial expression classification** (5 or 8 classes). Includes staged fine-tuning, mixed precision, metric logging, and checkpointing.

---

## 1Ô∏è‚É£ Environment

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
pip install opencv-python pandas numpy tqdm
```


Ensure `emonet.models.EmoNet` is accessible (e.g., via `PYTHONPATH` or editable install).

---

## 2Ô∏è‚É£ Data Format

Two CSV files: **train** and **test**.

| column    | type  | description                           |
| --------- | ----- | ------------------------------------- |
| `pth`     | str   | image path (relative to `--*_root`)   |
| `valence` | float | target in [-1,1]                      |
| `arousal` | float | target in [-1,1]                      |
| `label`   | str   | expression (required if `--use_expr`) |

**Expression sets:**

* 8-class: `neutral, happy, sad, surprise, fear, disgust, anger, contempt`
* 5-class: `neutral, happy, sad, surprise, fear`

```csv
pth,label,valence,arousal
img1.jpg,happy,0.6,0.4
img2.jpg,sad,-0.4,0.1
```

---

## 3Ô∏è‚É£ Pretrained Weights

Automatically loads if found:

```
pretrained/emonet_5.pth
pretrained/emonet_8.pth
```

---

## 4Ô∏è‚É£ Core Idea

* **Backbone**: frozen EmoNet feature extractor.
* **Heads**:

  * VA: CCC loss for valence & arousal.
  * Expr (optional): CrossEntropy loss.
* **Total Loss** = VA loss + Œª √ó Expr loss.
* Optional **unfreeze** backbone after N epochs to fine-tune fully.

---

## 5Ô∏è‚É£ Usage

### VA only

```bash
python train_emonet.py \
  --train_csv data/train.csv --test_csv data/val.csv \
  --train_root data/images --test_root data/images \
  --nclasses 8 --epochs 40 --batch 32
```

### VA + Expr

```bash
python train_emonet.py \
  --train_csv data/train.csv --test_csv data/val.csv \
  --train_root data/images --test_root data/images \
  --nclasses 8 --use_expr --lambda_expr 1.0
```

### Mixed Precision + Unfreeze

```bash
python train_emonet.py ... --amp --unfreeze_backbone_after 10
```

Key args:

* `--train_csv`, `--test_csv`, `--train_root`, `--test_root` ‚Äî dataset paths
* `--nclasses {5,8}` ‚Äî expression head size
* `--use_expr` ‚Äî enable expression training
* `--epochs`, `--batch`, `--lr`, `--amp` ‚Äî training settings
* `--unfreeze_backbone_after` ‚Äî staged fine-tuning

---

## 6Ô∏è‚É£ Outputs

Saved under `--outdir` (default `runs/emonet_train/`):

* `ckpt_best.pth` ‚Äî best by `ccc_mean`
* `metrics.csv` ‚Äî per-epoch metrics (losses, CCC, RMSE, MAE, expr acc)
* `emonet_<N>_finetuned.pth` ‚Äî final model

---

## 7Ô∏è‚É£ Tips

* Start with **frozen backbone**, unfreeze later if dataset is large or different.
* Monitor **`ccc_mean`** (main VA metric).
* Use `--amp` to reduce GPU memory.
* Label set must match canonical 5/8 classes.

---

## 8Ô∏è‚É£ Example Full Command

```bash
python train_emonet.py \
  --train_csv data/train.csv --test_csv data/val.csv \
  --train_root data/img --test_root data/img \
  --nclasses 8 --use_expr --lambda_expr 0.5 \
  --epochs 40 --batch 32 --lr 3e-4 \
  --amp --unfreeze_backbone_after 8 \
  --outdir runs/demo
```

---

## 9Ô∏è‚É£ Troubleshooting

* ‚ùå *Unknown labels* ‚Üí match canonical label set.
* ‚ùå *OOM errors* ‚Üí lower `--batch` or `--size`, enable `--amp`.
* ‚ùå *Divergence after unfreeze* ‚Üí lower LR or delay unfreeze.
* ‚úÖ Use `metrics.csv` to track progress over epochs.

---

## üîü Licensing

Follow EmoNet‚Äôs and dataset licenses. Ensure legal/ethical compliance for facial data use (e.g., GDPR).

```
```
